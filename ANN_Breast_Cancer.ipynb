{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Breast_Cancer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOLQexdpuBWkadvZNB8h5CX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ekayulianto/ANN_Breast_Cancer/blob/master/ANN_Breast_Cancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAFsz8gNTsBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "e0ca8e92-8dbb-44d5-cc17-79a5fda93872"
      },
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "\n",
        "\n",
        "#Score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5E6NH5chU1PX",
        "colab_type": "text"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTuin9mpUZ-o",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8cedef03-4e11-4507-e417-50cbaf37ac89"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-774b2fb1-a28b-48d4-b932-330807716f43\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-774b2fb1-a28b-48d4-b932-330807716f43\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving data.csv to data (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rn3V5ysU-tR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "318517a7-ae57-4b01-d648-75af041fa801"
      },
      "source": [
        " df = pd.read_csv('data.csv')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>Unnamed: 32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>842302</td>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.3001</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>842517</td>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.0869</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84300903</td>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.1974</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>84348301</td>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.2414</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>84358402</td>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.1980</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id diagnosis  ...  fractal_dimension_worst  Unnamed: 32\n",
              "0    842302         M  ...                  0.11890          NaN\n",
              "1    842517         M  ...                  0.08902          NaN\n",
              "2  84300903         M  ...                  0.08758          NaN\n",
              "3  84348301         M  ...                  0.17300          NaN\n",
              "4  84358402         M  ...                  0.07678          NaN\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noLGkZaLVGvG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "24661aba-b9da-4d82-b572-82fd429bfa8a"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 33 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            " 32  Unnamed: 32              0 non-null      float64\n",
            "dtypes: float64(31), int64(1), object(1)\n",
            "memory usage: 146.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oezj6zYaVJ4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop('Unnamed: 32', axis=1)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPjVo65jVcwV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "99dcb89e-8637-48ae-a430-103682d97224"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   id                       569 non-null    int64  \n",
            " 1   diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hntll78YVl6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.drop('id', axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAiiq3_mVzSx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "52b1bfc0-697e-43cd-b0f6-97b821c57c5c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   diagnosis                569 non-null    object \n",
            " 1   radius_mean              569 non-null    float64\n",
            " 2   texture_mean             569 non-null    float64\n",
            " 3   perimeter_mean           569 non-null    float64\n",
            " 4   area_mean                569 non-null    float64\n",
            " 5   smoothness_mean          569 non-null    float64\n",
            " 6   compactness_mean         569 non-null    float64\n",
            " 7   concavity_mean           569 non-null    float64\n",
            " 8   concave points_mean      569 non-null    float64\n",
            " 9   symmetry_mean            569 non-null    float64\n",
            " 10  fractal_dimension_mean   569 non-null    float64\n",
            " 11  radius_se                569 non-null    float64\n",
            " 12  texture_se               569 non-null    float64\n",
            " 13  perimeter_se             569 non-null    float64\n",
            " 14  area_se                  569 non-null    float64\n",
            " 15  smoothness_se            569 non-null    float64\n",
            " 16  compactness_se           569 non-null    float64\n",
            " 17  concavity_se             569 non-null    float64\n",
            " 18  concave points_se        569 non-null    float64\n",
            " 19  symmetry_se              569 non-null    float64\n",
            " 20  fractal_dimension_se     569 non-null    float64\n",
            " 21  radius_worst             569 non-null    float64\n",
            " 22  texture_worst            569 non-null    float64\n",
            " 23  perimeter_worst          569 non-null    float64\n",
            " 24  area_worst               569 non-null    float64\n",
            " 25  smoothness_worst         569 non-null    float64\n",
            " 26  compactness_worst        569 non-null    float64\n",
            " 27  concavity_worst          569 non-null    float64\n",
            " 28  concave points_worst     569 non-null    float64\n",
            " 29  symmetry_worst           569 non-null    float64\n",
            " 30  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), object(1)\n",
            "memory usage: 137.9+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1lBfikyV4Ib",
        "colab_type": "text"
      },
      "source": [
        "## Handling Missing Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hh1ChnBWV0Pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import missingno as msno\n",
        "def null_values(df):\n",
        "        mis_val = df.isnull().sum()\n",
        "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
        "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
        "        mis_val_table_ren_columns = mis_val_table.rename(\n",
        "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
        "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
        "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
        "        '% of Total Values', ascending=False).round(1)\n",
        "        print (\"Dataframe has \" + str(df.shape[1]) + \" columns.\\n\"      \n",
        "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
        "              \" columns that have missing values.\")\n",
        "        return mis_val_table_ren_columns"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrJpEnkkV_CC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "b6d7bc8f-3d1d-4bf5-ddd7-8174e9705dfd"
      },
      "source": [
        "miss_values = null_values(df)\n",
        "miss_values"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataframe has 31 columns.\n",
            "There are 0 columns that have missing values.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Missing Values</th>\n",
              "      <th>% of Total Values</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Missing Values, % of Total Values]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5Gcte5RWFec",
        "colab_type": "text"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKcW5hTUWCHF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e54928f8-c191-4ecf-88f5-0bce5039954a"
      },
      "source": [
        "df.diagnosis.value_counts()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "B    357\n",
              "M    212\n",
              "Name: diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nlf6JpuXIHT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "182540d8-167f-40fb-a01f-780f47b08955"
      },
      "source": [
        "df.diagnosis"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      M\n",
              "1      M\n",
              "2      M\n",
              "3      M\n",
              "4      M\n",
              "      ..\n",
              "564    M\n",
              "565    M\n",
              "566    M\n",
              "567    M\n",
              "568    B\n",
              "Name: diagnosis, Length: 569, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26y1TbnnWaXG",
        "colab_type": "text"
      },
      "source": [
        "### Label Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjpAlfmsWTIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencoder_diagnosa = LabelEncoder()\n",
        "df['label_diagnosis'] = labelencoder_diagnosa.fit_transform(df.diagnosis.values)\n",
        "## Note: M = 1, dan B = 0"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HD5Fx3snXqPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "187f7efd-3e86-43e0-9fe6-022c6ba17eb4"
      },
      "source": [
        "df.head(20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diagnosis</th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "      <th>label_diagnosis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>M</td>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.049040</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.015870</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.38</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.1622</td>\n",
              "      <td>0.6656</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.26540</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>M</td>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.013400</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.99</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.1238</td>\n",
              "      <td>0.1866</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.18600</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>M</td>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.040060</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.020580</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.57</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.1444</td>\n",
              "      <td>0.4245</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.24300</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>M</td>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.074580</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.018670</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.91</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.2098</td>\n",
              "      <td>0.8663</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.25750</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>M</td>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.024610</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.018850</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.54</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.1374</td>\n",
              "      <td>0.2050</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.16250</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>M</td>\n",
              "      <td>12.45</td>\n",
              "      <td>15.70</td>\n",
              "      <td>82.57</td>\n",
              "      <td>477.1</td>\n",
              "      <td>0.12780</td>\n",
              "      <td>0.17000</td>\n",
              "      <td>0.15780</td>\n",
              "      <td>0.08089</td>\n",
              "      <td>0.2087</td>\n",
              "      <td>0.07613</td>\n",
              "      <td>0.3345</td>\n",
              "      <td>0.8902</td>\n",
              "      <td>2.217</td>\n",
              "      <td>27.19</td>\n",
              "      <td>0.007510</td>\n",
              "      <td>0.033450</td>\n",
              "      <td>0.03672</td>\n",
              "      <td>0.011370</td>\n",
              "      <td>0.02165</td>\n",
              "      <td>0.005082</td>\n",
              "      <td>15.47</td>\n",
              "      <td>23.75</td>\n",
              "      <td>103.40</td>\n",
              "      <td>741.6</td>\n",
              "      <td>0.1791</td>\n",
              "      <td>0.5249</td>\n",
              "      <td>0.5355</td>\n",
              "      <td>0.17410</td>\n",
              "      <td>0.3985</td>\n",
              "      <td>0.12440</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>M</td>\n",
              "      <td>18.25</td>\n",
              "      <td>19.98</td>\n",
              "      <td>119.60</td>\n",
              "      <td>1040.0</td>\n",
              "      <td>0.09463</td>\n",
              "      <td>0.10900</td>\n",
              "      <td>0.11270</td>\n",
              "      <td>0.07400</td>\n",
              "      <td>0.1794</td>\n",
              "      <td>0.05742</td>\n",
              "      <td>0.4467</td>\n",
              "      <td>0.7732</td>\n",
              "      <td>3.180</td>\n",
              "      <td>53.91</td>\n",
              "      <td>0.004314</td>\n",
              "      <td>0.013820</td>\n",
              "      <td>0.02254</td>\n",
              "      <td>0.010390</td>\n",
              "      <td>0.01369</td>\n",
              "      <td>0.002179</td>\n",
              "      <td>22.88</td>\n",
              "      <td>27.66</td>\n",
              "      <td>153.20</td>\n",
              "      <td>1606.0</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2576</td>\n",
              "      <td>0.3784</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>0.08368</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>M</td>\n",
              "      <td>13.71</td>\n",
              "      <td>20.83</td>\n",
              "      <td>90.20</td>\n",
              "      <td>577.9</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.16450</td>\n",
              "      <td>0.09366</td>\n",
              "      <td>0.05985</td>\n",
              "      <td>0.2196</td>\n",
              "      <td>0.07451</td>\n",
              "      <td>0.5835</td>\n",
              "      <td>1.3770</td>\n",
              "      <td>3.856</td>\n",
              "      <td>50.96</td>\n",
              "      <td>0.008805</td>\n",
              "      <td>0.030290</td>\n",
              "      <td>0.02488</td>\n",
              "      <td>0.014480</td>\n",
              "      <td>0.01486</td>\n",
              "      <td>0.005412</td>\n",
              "      <td>17.06</td>\n",
              "      <td>28.14</td>\n",
              "      <td>110.60</td>\n",
              "      <td>897.0</td>\n",
              "      <td>0.1654</td>\n",
              "      <td>0.3682</td>\n",
              "      <td>0.2678</td>\n",
              "      <td>0.15560</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.11510</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>M</td>\n",
              "      <td>13.00</td>\n",
              "      <td>21.82</td>\n",
              "      <td>87.50</td>\n",
              "      <td>519.8</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.19320</td>\n",
              "      <td>0.18590</td>\n",
              "      <td>0.09353</td>\n",
              "      <td>0.2350</td>\n",
              "      <td>0.07389</td>\n",
              "      <td>0.3063</td>\n",
              "      <td>1.0020</td>\n",
              "      <td>2.406</td>\n",
              "      <td>24.32</td>\n",
              "      <td>0.005731</td>\n",
              "      <td>0.035020</td>\n",
              "      <td>0.03553</td>\n",
              "      <td>0.012260</td>\n",
              "      <td>0.02143</td>\n",
              "      <td>0.003749</td>\n",
              "      <td>15.49</td>\n",
              "      <td>30.73</td>\n",
              "      <td>106.20</td>\n",
              "      <td>739.3</td>\n",
              "      <td>0.1703</td>\n",
              "      <td>0.5401</td>\n",
              "      <td>0.5390</td>\n",
              "      <td>0.20600</td>\n",
              "      <td>0.4378</td>\n",
              "      <td>0.10720</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>M</td>\n",
              "      <td>12.46</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.94</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.014320</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.09</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.1853</td>\n",
              "      <td>1.0580</td>\n",
              "      <td>1.1050</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>M</td>\n",
              "      <td>16.02</td>\n",
              "      <td>23.24</td>\n",
              "      <td>102.70</td>\n",
              "      <td>797.8</td>\n",
              "      <td>0.08206</td>\n",
              "      <td>0.06669</td>\n",
              "      <td>0.03299</td>\n",
              "      <td>0.03323</td>\n",
              "      <td>0.1528</td>\n",
              "      <td>0.05697</td>\n",
              "      <td>0.3795</td>\n",
              "      <td>1.1870</td>\n",
              "      <td>2.466</td>\n",
              "      <td>40.51</td>\n",
              "      <td>0.004029</td>\n",
              "      <td>0.009269</td>\n",
              "      <td>0.01101</td>\n",
              "      <td>0.007591</td>\n",
              "      <td>0.01460</td>\n",
              "      <td>0.003042</td>\n",
              "      <td>19.19</td>\n",
              "      <td>33.88</td>\n",
              "      <td>123.80</td>\n",
              "      <td>1150.0</td>\n",
              "      <td>0.1181</td>\n",
              "      <td>0.1551</td>\n",
              "      <td>0.1459</td>\n",
              "      <td>0.09975</td>\n",
              "      <td>0.2948</td>\n",
              "      <td>0.08452</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>M</td>\n",
              "      <td>15.78</td>\n",
              "      <td>17.89</td>\n",
              "      <td>103.60</td>\n",
              "      <td>781.0</td>\n",
              "      <td>0.09710</td>\n",
              "      <td>0.12920</td>\n",
              "      <td>0.09954</td>\n",
              "      <td>0.06606</td>\n",
              "      <td>0.1842</td>\n",
              "      <td>0.06082</td>\n",
              "      <td>0.5058</td>\n",
              "      <td>0.9849</td>\n",
              "      <td>3.564</td>\n",
              "      <td>54.16</td>\n",
              "      <td>0.005771</td>\n",
              "      <td>0.040610</td>\n",
              "      <td>0.02791</td>\n",
              "      <td>0.012820</td>\n",
              "      <td>0.02008</td>\n",
              "      <td>0.004144</td>\n",
              "      <td>20.42</td>\n",
              "      <td>27.28</td>\n",
              "      <td>136.50</td>\n",
              "      <td>1299.0</td>\n",
              "      <td>0.1396</td>\n",
              "      <td>0.5609</td>\n",
              "      <td>0.3965</td>\n",
              "      <td>0.18100</td>\n",
              "      <td>0.3792</td>\n",
              "      <td>0.10480</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>M</td>\n",
              "      <td>19.17</td>\n",
              "      <td>24.80</td>\n",
              "      <td>132.40</td>\n",
              "      <td>1123.0</td>\n",
              "      <td>0.09740</td>\n",
              "      <td>0.24580</td>\n",
              "      <td>0.20650</td>\n",
              "      <td>0.11180</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07800</td>\n",
              "      <td>0.9555</td>\n",
              "      <td>3.5680</td>\n",
              "      <td>11.070</td>\n",
              "      <td>116.20</td>\n",
              "      <td>0.003139</td>\n",
              "      <td>0.082970</td>\n",
              "      <td>0.08890</td>\n",
              "      <td>0.040900</td>\n",
              "      <td>0.04484</td>\n",
              "      <td>0.012840</td>\n",
              "      <td>20.96</td>\n",
              "      <td>29.94</td>\n",
              "      <td>151.70</td>\n",
              "      <td>1332.0</td>\n",
              "      <td>0.1037</td>\n",
              "      <td>0.3903</td>\n",
              "      <td>0.3639</td>\n",
              "      <td>0.17670</td>\n",
              "      <td>0.3176</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>M</td>\n",
              "      <td>15.85</td>\n",
              "      <td>23.95</td>\n",
              "      <td>103.70</td>\n",
              "      <td>782.7</td>\n",
              "      <td>0.08401</td>\n",
              "      <td>0.10020</td>\n",
              "      <td>0.09938</td>\n",
              "      <td>0.05364</td>\n",
              "      <td>0.1847</td>\n",
              "      <td>0.05338</td>\n",
              "      <td>0.4033</td>\n",
              "      <td>1.0780</td>\n",
              "      <td>2.903</td>\n",
              "      <td>36.58</td>\n",
              "      <td>0.009769</td>\n",
              "      <td>0.031260</td>\n",
              "      <td>0.05051</td>\n",
              "      <td>0.019920</td>\n",
              "      <td>0.02981</td>\n",
              "      <td>0.003002</td>\n",
              "      <td>16.84</td>\n",
              "      <td>27.66</td>\n",
              "      <td>112.00</td>\n",
              "      <td>876.5</td>\n",
              "      <td>0.1131</td>\n",
              "      <td>0.1924</td>\n",
              "      <td>0.2322</td>\n",
              "      <td>0.11190</td>\n",
              "      <td>0.2809</td>\n",
              "      <td>0.06287</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>M</td>\n",
              "      <td>13.73</td>\n",
              "      <td>22.61</td>\n",
              "      <td>93.60</td>\n",
              "      <td>578.3</td>\n",
              "      <td>0.11310</td>\n",
              "      <td>0.22930</td>\n",
              "      <td>0.21280</td>\n",
              "      <td>0.08025</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.07682</td>\n",
              "      <td>0.2121</td>\n",
              "      <td>1.1690</td>\n",
              "      <td>2.061</td>\n",
              "      <td>19.21</td>\n",
              "      <td>0.006429</td>\n",
              "      <td>0.059360</td>\n",
              "      <td>0.05501</td>\n",
              "      <td>0.016280</td>\n",
              "      <td>0.01961</td>\n",
              "      <td>0.008093</td>\n",
              "      <td>15.03</td>\n",
              "      <td>32.01</td>\n",
              "      <td>108.80</td>\n",
              "      <td>697.7</td>\n",
              "      <td>0.1651</td>\n",
              "      <td>0.7725</td>\n",
              "      <td>0.6943</td>\n",
              "      <td>0.22080</td>\n",
              "      <td>0.3596</td>\n",
              "      <td>0.14310</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>M</td>\n",
              "      <td>14.54</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.16390</td>\n",
              "      <td>0.07364</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>0.07077</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>1.0330</td>\n",
              "      <td>2.879</td>\n",
              "      <td>32.55</td>\n",
              "      <td>0.005607</td>\n",
              "      <td>0.042400</td>\n",
              "      <td>0.04741</td>\n",
              "      <td>0.010900</td>\n",
              "      <td>0.01857</td>\n",
              "      <td>0.005466</td>\n",
              "      <td>17.46</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.1678</td>\n",
              "      <td>0.6577</td>\n",
              "      <td>0.7026</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>M</td>\n",
              "      <td>14.68</td>\n",
              "      <td>20.13</td>\n",
              "      <td>94.74</td>\n",
              "      <td>684.5</td>\n",
              "      <td>0.09867</td>\n",
              "      <td>0.07200</td>\n",
              "      <td>0.07395</td>\n",
              "      <td>0.05259</td>\n",
              "      <td>0.1586</td>\n",
              "      <td>0.05922</td>\n",
              "      <td>0.4727</td>\n",
              "      <td>1.2400</td>\n",
              "      <td>3.195</td>\n",
              "      <td>45.40</td>\n",
              "      <td>0.005718</td>\n",
              "      <td>0.011620</td>\n",
              "      <td>0.01998</td>\n",
              "      <td>0.011090</td>\n",
              "      <td>0.01410</td>\n",
              "      <td>0.002085</td>\n",
              "      <td>19.07</td>\n",
              "      <td>30.88</td>\n",
              "      <td>123.40</td>\n",
              "      <td>1138.0</td>\n",
              "      <td>0.1464</td>\n",
              "      <td>0.1871</td>\n",
              "      <td>0.2914</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.3029</td>\n",
              "      <td>0.08216</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>M</td>\n",
              "      <td>16.13</td>\n",
              "      <td>20.68</td>\n",
              "      <td>108.10</td>\n",
              "      <td>798.8</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.20220</td>\n",
              "      <td>0.17220</td>\n",
              "      <td>0.10280</td>\n",
              "      <td>0.2164</td>\n",
              "      <td>0.07356</td>\n",
              "      <td>0.5692</td>\n",
              "      <td>1.0730</td>\n",
              "      <td>3.854</td>\n",
              "      <td>54.18</td>\n",
              "      <td>0.007026</td>\n",
              "      <td>0.025010</td>\n",
              "      <td>0.03188</td>\n",
              "      <td>0.012970</td>\n",
              "      <td>0.01689</td>\n",
              "      <td>0.004142</td>\n",
              "      <td>20.96</td>\n",
              "      <td>31.48</td>\n",
              "      <td>136.80</td>\n",
              "      <td>1315.0</td>\n",
              "      <td>0.1789</td>\n",
              "      <td>0.4233</td>\n",
              "      <td>0.4784</td>\n",
              "      <td>0.20730</td>\n",
              "      <td>0.3706</td>\n",
              "      <td>0.11420</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>M</td>\n",
              "      <td>19.81</td>\n",
              "      <td>22.15</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1260.0</td>\n",
              "      <td>0.09831</td>\n",
              "      <td>0.10270</td>\n",
              "      <td>0.14790</td>\n",
              "      <td>0.09498</td>\n",
              "      <td>0.1582</td>\n",
              "      <td>0.05395</td>\n",
              "      <td>0.7582</td>\n",
              "      <td>1.0170</td>\n",
              "      <td>5.865</td>\n",
              "      <td>112.40</td>\n",
              "      <td>0.006494</td>\n",
              "      <td>0.018930</td>\n",
              "      <td>0.03391</td>\n",
              "      <td>0.015210</td>\n",
              "      <td>0.01356</td>\n",
              "      <td>0.001997</td>\n",
              "      <td>27.32</td>\n",
              "      <td>30.88</td>\n",
              "      <td>186.80</td>\n",
              "      <td>2398.0</td>\n",
              "      <td>0.1512</td>\n",
              "      <td>0.3150</td>\n",
              "      <td>0.5372</td>\n",
              "      <td>0.23880</td>\n",
              "      <td>0.2768</td>\n",
              "      <td>0.07615</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>B</td>\n",
              "      <td>13.54</td>\n",
              "      <td>14.36</td>\n",
              "      <td>87.46</td>\n",
              "      <td>566.3</td>\n",
              "      <td>0.09779</td>\n",
              "      <td>0.08129</td>\n",
              "      <td>0.06664</td>\n",
              "      <td>0.04781</td>\n",
              "      <td>0.1885</td>\n",
              "      <td>0.05766</td>\n",
              "      <td>0.2699</td>\n",
              "      <td>0.7886</td>\n",
              "      <td>2.058</td>\n",
              "      <td>23.56</td>\n",
              "      <td>0.008462</td>\n",
              "      <td>0.014600</td>\n",
              "      <td>0.02387</td>\n",
              "      <td>0.013150</td>\n",
              "      <td>0.01980</td>\n",
              "      <td>0.002300</td>\n",
              "      <td>15.11</td>\n",
              "      <td>19.26</td>\n",
              "      <td>99.70</td>\n",
              "      <td>711.2</td>\n",
              "      <td>0.1440</td>\n",
              "      <td>0.1773</td>\n",
              "      <td>0.2390</td>\n",
              "      <td>0.12880</td>\n",
              "      <td>0.2977</td>\n",
              "      <td>0.07259</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   diagnosis  radius_mean  ...  fractal_dimension_worst  label_diagnosis\n",
              "0          M        17.99  ...                  0.11890                1\n",
              "1          M        20.57  ...                  0.08902                1\n",
              "2          M        19.69  ...                  0.08758                1\n",
              "3          M        11.42  ...                  0.17300                1\n",
              "4          M        20.29  ...                  0.07678                1\n",
              "5          M        12.45  ...                  0.12440                1\n",
              "6          M        18.25  ...                  0.08368                1\n",
              "7          M        13.71  ...                  0.11510                1\n",
              "8          M        13.00  ...                  0.10720                1\n",
              "9          M        12.46  ...                  0.20750                1\n",
              "10         M        16.02  ...                  0.08452                1\n",
              "11         M        15.78  ...                  0.10480                1\n",
              "12         M        19.17  ...                  0.10230                1\n",
              "13         M        15.85  ...                  0.06287                1\n",
              "14         M        13.73  ...                  0.14310                1\n",
              "15         M        14.54  ...                  0.13410                1\n",
              "16         M        14.68  ...                  0.08216                1\n",
              "17         M        16.13  ...                  0.11420                1\n",
              "18         M        19.81  ...                  0.07615                1\n",
              "19         B        13.54  ...                  0.07259                0\n",
              "\n",
              "[20 rows x 32 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YgPMYxiPXrl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "d8793257-07bb-4b7b-b6e4-09dd1d776d23"
      },
      "source": [
        "## drop kolom diagnosis\n",
        "df = df.drop('diagnosis', axis=1)\n",
        "df.info()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   radius_mean              569 non-null    float64\n",
            " 1   texture_mean             569 non-null    float64\n",
            " 2   perimeter_mean           569 non-null    float64\n",
            " 3   area_mean                569 non-null    float64\n",
            " 4   smoothness_mean          569 non-null    float64\n",
            " 5   compactness_mean         569 non-null    float64\n",
            " 6   concavity_mean           569 non-null    float64\n",
            " 7   concave points_mean      569 non-null    float64\n",
            " 8   symmetry_mean            569 non-null    float64\n",
            " 9   fractal_dimension_mean   569 non-null    float64\n",
            " 10  radius_se                569 non-null    float64\n",
            " 11  texture_se               569 non-null    float64\n",
            " 12  perimeter_se             569 non-null    float64\n",
            " 13  area_se                  569 non-null    float64\n",
            " 14  smoothness_se            569 non-null    float64\n",
            " 15  compactness_se           569 non-null    float64\n",
            " 16  concavity_se             569 non-null    float64\n",
            " 17  concave points_se        569 non-null    float64\n",
            " 18  symmetry_se              569 non-null    float64\n",
            " 19  fractal_dimension_se     569 non-null    float64\n",
            " 20  radius_worst             569 non-null    float64\n",
            " 21  texture_worst            569 non-null    float64\n",
            " 22  perimeter_worst          569 non-null    float64\n",
            " 23  area_worst               569 non-null    float64\n",
            " 24  smoothness_worst         569 non-null    float64\n",
            " 25  compactness_worst        569 non-null    float64\n",
            " 26  concavity_worst          569 non-null    float64\n",
            " 27  concave points_worst     569 non-null    float64\n",
            " 28  symmetry_worst           569 non-null    float64\n",
            " 29  fractal_dimension_worst  569 non-null    float64\n",
            " 30  label_diagnosis          569 non-null    int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 137.9 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YgZTU3TYVWd",
        "colab_type": "text"
      },
      "source": [
        "## Split Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fX2sAwwiYCfI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.drop('label_diagnosis', axis=1)\n",
        "y = df['label_diagnosis']"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EvGyFk6Ygyy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "outputId": "38a191af-45b4-45c5-d284-b50250390ac2"
      },
      "source": [
        "X.info()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   radius_mean              569 non-null    float64\n",
            " 1   texture_mean             569 non-null    float64\n",
            " 2   perimeter_mean           569 non-null    float64\n",
            " 3   area_mean                569 non-null    float64\n",
            " 4   smoothness_mean          569 non-null    float64\n",
            " 5   compactness_mean         569 non-null    float64\n",
            " 6   concavity_mean           569 non-null    float64\n",
            " 7   concave points_mean      569 non-null    float64\n",
            " 8   symmetry_mean            569 non-null    float64\n",
            " 9   fractal_dimension_mean   569 non-null    float64\n",
            " 10  radius_se                569 non-null    float64\n",
            " 11  texture_se               569 non-null    float64\n",
            " 12  perimeter_se             569 non-null    float64\n",
            " 13  area_se                  569 non-null    float64\n",
            " 14  smoothness_se            569 non-null    float64\n",
            " 15  compactness_se           569 non-null    float64\n",
            " 16  concavity_se             569 non-null    float64\n",
            " 17  concave points_se        569 non-null    float64\n",
            " 18  symmetry_se              569 non-null    float64\n",
            " 19  fractal_dimension_se     569 non-null    float64\n",
            " 20  radius_worst             569 non-null    float64\n",
            " 21  texture_worst            569 non-null    float64\n",
            " 22  perimeter_worst          569 non-null    float64\n",
            " 23  area_worst               569 non-null    float64\n",
            " 24  smoothness_worst         569 non-null    float64\n",
            " 25  compactness_worst        569 non-null    float64\n",
            " 26  concavity_worst          569 non-null    float64\n",
            " 27  concave points_worst     569 non-null    float64\n",
            " 28  symmetry_worst           569 non-null    float64\n",
            " 29  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsrSDQ-6Yh8R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6d70c6fd-52b5-45a7-d5a9-da127ce5d221"
      },
      "source": [
        "y"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      1\n",
              "1      1\n",
              "2      1\n",
              "3      1\n",
              "4      1\n",
              "      ..\n",
              "564    1\n",
              "565    1\n",
              "566    1\n",
              "567    1\n",
              "568    0\n",
              "Name: label_diagnosis, Length: 569, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4e-pdxUYrUE",
        "colab_type": "text"
      },
      "source": [
        "### Splitting data into Training Set and Test Set (Training = 70%, Tes = 30%)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0_-THs7eYo1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = 0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNMeEhKdZCQx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0ff93a9-9542-4ace-8a06-700f8f8df359"
      },
      "source": [
        "unique, counts = np.unique(y_train, return_counts=True)         #menghitung jumlah status(y) pd data training\n",
        "dict(zip(unique, counts))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 249, 1: 149}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K08CoYEDZSXX",
        "colab_type": "text"
      },
      "source": [
        "## Feature Scalling (Standardization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5q7xTmoXCudN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_no_norm = X_train.copy()\n",
        "X_test_no_norm = X_test.copy()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfVGUUEbD0Od",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "621b5649-bce3-4464-d4ee-58c76724d619"
      },
      "source": [
        "X_train_no_norm"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>radius_mean</th>\n",
              "      <th>texture_mean</th>\n",
              "      <th>perimeter_mean</th>\n",
              "      <th>area_mean</th>\n",
              "      <th>smoothness_mean</th>\n",
              "      <th>compactness_mean</th>\n",
              "      <th>concavity_mean</th>\n",
              "      <th>concave points_mean</th>\n",
              "      <th>symmetry_mean</th>\n",
              "      <th>fractal_dimension_mean</th>\n",
              "      <th>radius_se</th>\n",
              "      <th>texture_se</th>\n",
              "      <th>perimeter_se</th>\n",
              "      <th>area_se</th>\n",
              "      <th>smoothness_se</th>\n",
              "      <th>compactness_se</th>\n",
              "      <th>concavity_se</th>\n",
              "      <th>concave points_se</th>\n",
              "      <th>symmetry_se</th>\n",
              "      <th>fractal_dimension_se</th>\n",
              "      <th>radius_worst</th>\n",
              "      <th>texture_worst</th>\n",
              "      <th>perimeter_worst</th>\n",
              "      <th>area_worst</th>\n",
              "      <th>smoothness_worst</th>\n",
              "      <th>compactness_worst</th>\n",
              "      <th>concavity_worst</th>\n",
              "      <th>concave points_worst</th>\n",
              "      <th>symmetry_worst</th>\n",
              "      <th>fractal_dimension_worst</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>11.490</td>\n",
              "      <td>14.59</td>\n",
              "      <td>73.99</td>\n",
              "      <td>404.9</td>\n",
              "      <td>0.10460</td>\n",
              "      <td>0.08228</td>\n",
              "      <td>0.05308</td>\n",
              "      <td>0.01969</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>0.06574</td>\n",
              "      <td>0.2034</td>\n",
              "      <td>1.1660</td>\n",
              "      <td>1.567</td>\n",
              "      <td>14.340</td>\n",
              "      <td>0.004957</td>\n",
              "      <td>0.021140</td>\n",
              "      <td>0.04156</td>\n",
              "      <td>0.008038</td>\n",
              "      <td>0.01843</td>\n",
              "      <td>0.003614</td>\n",
              "      <td>12.400</td>\n",
              "      <td>21.90</td>\n",
              "      <td>82.04</td>\n",
              "      <td>467.6</td>\n",
              "      <td>0.13520</td>\n",
              "      <td>0.20100</td>\n",
              "      <td>0.25960</td>\n",
              "      <td>0.07431</td>\n",
              "      <td>0.2941</td>\n",
              "      <td>0.09180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>10.490</td>\n",
              "      <td>18.61</td>\n",
              "      <td>66.86</td>\n",
              "      <td>334.3</td>\n",
              "      <td>0.10680</td>\n",
              "      <td>0.06678</td>\n",
              "      <td>0.02297</td>\n",
              "      <td>0.01780</td>\n",
              "      <td>0.1482</td>\n",
              "      <td>0.06600</td>\n",
              "      <td>0.1485</td>\n",
              "      <td>1.5630</td>\n",
              "      <td>1.035</td>\n",
              "      <td>10.080</td>\n",
              "      <td>0.008875</td>\n",
              "      <td>0.009362</td>\n",
              "      <td>0.01808</td>\n",
              "      <td>0.009199</td>\n",
              "      <td>0.01791</td>\n",
              "      <td>0.003317</td>\n",
              "      <td>11.060</td>\n",
              "      <td>24.54</td>\n",
              "      <td>70.76</td>\n",
              "      <td>375.4</td>\n",
              "      <td>0.14130</td>\n",
              "      <td>0.10440</td>\n",
              "      <td>0.08423</td>\n",
              "      <td>0.06528</td>\n",
              "      <td>0.2213</td>\n",
              "      <td>0.07842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>12.250</td>\n",
              "      <td>17.94</td>\n",
              "      <td>78.27</td>\n",
              "      <td>460.3</td>\n",
              "      <td>0.08654</td>\n",
              "      <td>0.06679</td>\n",
              "      <td>0.03885</td>\n",
              "      <td>0.02331</td>\n",
              "      <td>0.1970</td>\n",
              "      <td>0.06228</td>\n",
              "      <td>0.2200</td>\n",
              "      <td>0.9823</td>\n",
              "      <td>1.484</td>\n",
              "      <td>16.510</td>\n",
              "      <td>0.005518</td>\n",
              "      <td>0.015620</td>\n",
              "      <td>0.01994</td>\n",
              "      <td>0.007924</td>\n",
              "      <td>0.01799</td>\n",
              "      <td>0.002484</td>\n",
              "      <td>13.590</td>\n",
              "      <td>25.22</td>\n",
              "      <td>86.60</td>\n",
              "      <td>564.2</td>\n",
              "      <td>0.12170</td>\n",
              "      <td>0.17880</td>\n",
              "      <td>0.19430</td>\n",
              "      <td>0.08211</td>\n",
              "      <td>0.3113</td>\n",
              "      <td>0.08132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>18.310</td>\n",
              "      <td>18.58</td>\n",
              "      <td>118.60</td>\n",
              "      <td>1041.0</td>\n",
              "      <td>0.08588</td>\n",
              "      <td>0.08468</td>\n",
              "      <td>0.08169</td>\n",
              "      <td>0.05814</td>\n",
              "      <td>0.1621</td>\n",
              "      <td>0.05425</td>\n",
              "      <td>0.2577</td>\n",
              "      <td>0.4757</td>\n",
              "      <td>1.817</td>\n",
              "      <td>28.920</td>\n",
              "      <td>0.002866</td>\n",
              "      <td>0.009181</td>\n",
              "      <td>0.01412</td>\n",
              "      <td>0.006719</td>\n",
              "      <td>0.01069</td>\n",
              "      <td>0.001087</td>\n",
              "      <td>21.310</td>\n",
              "      <td>26.36</td>\n",
              "      <td>139.20</td>\n",
              "      <td>1410.0</td>\n",
              "      <td>0.12340</td>\n",
              "      <td>0.24450</td>\n",
              "      <td>0.35380</td>\n",
              "      <td>0.15710</td>\n",
              "      <td>0.3206</td>\n",
              "      <td>0.06938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>6.981</td>\n",
              "      <td>13.43</td>\n",
              "      <td>43.79</td>\n",
              "      <td>143.5</td>\n",
              "      <td>0.11700</td>\n",
              "      <td>0.07568</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1930</td>\n",
              "      <td>0.07818</td>\n",
              "      <td>0.2241</td>\n",
              "      <td>1.5080</td>\n",
              "      <td>1.553</td>\n",
              "      <td>9.833</td>\n",
              "      <td>0.010190</td>\n",
              "      <td>0.010840</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.02659</td>\n",
              "      <td>0.004100</td>\n",
              "      <td>7.930</td>\n",
              "      <td>19.54</td>\n",
              "      <td>50.41</td>\n",
              "      <td>185.2</td>\n",
              "      <td>0.15840</td>\n",
              "      <td>0.12020</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.2932</td>\n",
              "      <td>0.09382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>18.810</td>\n",
              "      <td>19.98</td>\n",
              "      <td>120.90</td>\n",
              "      <td>1102.0</td>\n",
              "      <td>0.08923</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.08020</td>\n",
              "      <td>0.05843</td>\n",
              "      <td>0.1550</td>\n",
              "      <td>0.04996</td>\n",
              "      <td>0.3283</td>\n",
              "      <td>0.8280</td>\n",
              "      <td>2.363</td>\n",
              "      <td>36.740</td>\n",
              "      <td>0.007571</td>\n",
              "      <td>0.011140</td>\n",
              "      <td>0.02623</td>\n",
              "      <td>0.014630</td>\n",
              "      <td>0.01930</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>19.960</td>\n",
              "      <td>24.30</td>\n",
              "      <td>129.00</td>\n",
              "      <td>1236.0</td>\n",
              "      <td>0.12430</td>\n",
              "      <td>0.11600</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.12940</td>\n",
              "      <td>0.2567</td>\n",
              "      <td>0.05737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>12.460</td>\n",
              "      <td>24.04</td>\n",
              "      <td>83.97</td>\n",
              "      <td>475.9</td>\n",
              "      <td>0.11860</td>\n",
              "      <td>0.23960</td>\n",
              "      <td>0.22730</td>\n",
              "      <td>0.08543</td>\n",
              "      <td>0.2030</td>\n",
              "      <td>0.08243</td>\n",
              "      <td>0.2976</td>\n",
              "      <td>1.5990</td>\n",
              "      <td>2.039</td>\n",
              "      <td>23.940</td>\n",
              "      <td>0.007149</td>\n",
              "      <td>0.072170</td>\n",
              "      <td>0.07743</td>\n",
              "      <td>0.014320</td>\n",
              "      <td>0.01789</td>\n",
              "      <td>0.010080</td>\n",
              "      <td>15.090</td>\n",
              "      <td>40.68</td>\n",
              "      <td>97.65</td>\n",
              "      <td>711.4</td>\n",
              "      <td>0.18530</td>\n",
              "      <td>1.05800</td>\n",
              "      <td>1.10500</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.4366</td>\n",
              "      <td>0.20750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>9.436</td>\n",
              "      <td>18.32</td>\n",
              "      <td>59.82</td>\n",
              "      <td>278.6</td>\n",
              "      <td>0.10090</td>\n",
              "      <td>0.05956</td>\n",
              "      <td>0.02710</td>\n",
              "      <td>0.01406</td>\n",
              "      <td>0.1506</td>\n",
              "      <td>0.06959</td>\n",
              "      <td>0.5079</td>\n",
              "      <td>1.2470</td>\n",
              "      <td>3.267</td>\n",
              "      <td>30.480</td>\n",
              "      <td>0.006836</td>\n",
              "      <td>0.008982</td>\n",
              "      <td>0.02348</td>\n",
              "      <td>0.006565</td>\n",
              "      <td>0.01942</td>\n",
              "      <td>0.002713</td>\n",
              "      <td>12.020</td>\n",
              "      <td>25.02</td>\n",
              "      <td>75.79</td>\n",
              "      <td>439.6</td>\n",
              "      <td>0.13330</td>\n",
              "      <td>0.10490</td>\n",
              "      <td>0.11440</td>\n",
              "      <td>0.05052</td>\n",
              "      <td>0.2454</td>\n",
              "      <td>0.08136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>9.720</td>\n",
              "      <td>18.22</td>\n",
              "      <td>60.73</td>\n",
              "      <td>288.1</td>\n",
              "      <td>0.06950</td>\n",
              "      <td>0.02344</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1653</td>\n",
              "      <td>0.06447</td>\n",
              "      <td>0.3539</td>\n",
              "      <td>4.8850</td>\n",
              "      <td>2.230</td>\n",
              "      <td>21.690</td>\n",
              "      <td>0.001713</td>\n",
              "      <td>0.006736</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.03799</td>\n",
              "      <td>0.001688</td>\n",
              "      <td>9.968</td>\n",
              "      <td>20.83</td>\n",
              "      <td>62.25</td>\n",
              "      <td>303.8</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1909</td>\n",
              "      <td>0.06559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>11.510</td>\n",
              "      <td>23.93</td>\n",
              "      <td>74.52</td>\n",
              "      <td>403.5</td>\n",
              "      <td>0.09261</td>\n",
              "      <td>0.10210</td>\n",
              "      <td>0.11120</td>\n",
              "      <td>0.04105</td>\n",
              "      <td>0.1388</td>\n",
              "      <td>0.06570</td>\n",
              "      <td>0.2388</td>\n",
              "      <td>2.9040</td>\n",
              "      <td>1.936</td>\n",
              "      <td>16.970</td>\n",
              "      <td>0.008200</td>\n",
              "      <td>0.029820</td>\n",
              "      <td>0.05738</td>\n",
              "      <td>0.012670</td>\n",
              "      <td>0.01488</td>\n",
              "      <td>0.004738</td>\n",
              "      <td>12.480</td>\n",
              "      <td>37.16</td>\n",
              "      <td>82.28</td>\n",
              "      <td>474.2</td>\n",
              "      <td>0.12980</td>\n",
              "      <td>0.25170</td>\n",
              "      <td>0.36300</td>\n",
              "      <td>0.09653</td>\n",
              "      <td>0.2112</td>\n",
              "      <td>0.08732</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     radius_mean  texture_mean  ...  symmetry_worst  fractal_dimension_worst\n",
              "478       11.490         14.59  ...          0.2941                  0.09180\n",
              "303       10.490         18.61  ...          0.2213                  0.07842\n",
              "155       12.250         17.94  ...          0.3113                  0.08132\n",
              "186       18.310         18.58  ...          0.3206                  0.06938\n",
              "101        6.981         13.43  ...          0.2932                  0.09382\n",
              "..           ...           ...  ...             ...                      ...\n",
              "277       18.810         19.98  ...          0.2567                  0.05737\n",
              "9         12.460         24.04  ...          0.4366                  0.20750\n",
              "359        9.436         18.32  ...          0.2454                  0.08136\n",
              "192        9.720         18.22  ...          0.1909                  0.06559\n",
              "559       11.510         23.93  ...          0.2112                  0.08732\n",
              "\n",
              "[398 rows x 30 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ceATvSaZFNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)           ## Standard Scaller of X_train\n",
        "X_test = sc.fit_transform(X_test)             ## Standard Scaller of X_test\n",
        "## Output berupa numpy"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5XdNOnJZoCM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "983318a8-09d8-4279-9853-fb249c5a437e"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.74998027, -1.09978744, -0.74158608, ..., -0.6235968 ,\n",
              "         0.07754241,  0.45062841],\n",
              "       [-1.02821446, -0.1392617 , -1.02980434, ..., -0.7612376 ,\n",
              "        -1.07145262, -0.29541379],\n",
              "       [-0.53852228, -0.29934933, -0.56857428, ..., -0.50470441,\n",
              "         0.34900827, -0.13371556],\n",
              "       ...,\n",
              "       [-1.3214733 , -0.20855336, -1.3143845 , ..., -0.98621857,\n",
              "        -0.69108476, -0.13148524],\n",
              "       [-1.24245479, -0.23244704, -1.27759928, ..., -1.7562754 ,\n",
              "        -1.55125275, -1.01078909],\n",
              "       [-0.74441558,  1.13188181, -0.72016173, ..., -0.28490593,\n",
              "        -1.2308599 ,  0.20083251]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfvfqpBnZpj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "fd95d0d2-2b46-4049-f685-dafa4f6fbc1a"
      },
      "source": [
        "X_test"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.17715788,  0.22140254, -0.10696857, ...,  1.39677786,\n",
              "         1.14404645,  1.44477141],\n",
              "       [-0.23403396,  1.26339611, -0.30309994, ..., -0.80720664,\n",
              "        -0.82315205, -0.90738698],\n",
              "       [ 0.00843776, -0.84922934, -0.06592787, ..., -0.47125285,\n",
              "        -1.35417496, -0.9500342 ],\n",
              "       ...,\n",
              "       [-0.08436006, -0.18393957, -0.10308051, ...,  0.23134793,\n",
              "        -0.12489141,  0.31899407],\n",
              "       [-0.20709266,  0.45271189, -0.2538511 , ..., -0.86661774,\n",
              "        -0.49040068, -0.97846568],\n",
              "       [-1.39460537,  0.53422091, -1.38700657, ..., -1.33005467,\n",
              "        -0.83866895, -0.57659762]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xk6QPIO-Zxp2",
        "colab_type": "text"
      },
      "source": [
        "## Building ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9sozj8yNcm2a",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9a7bd214-a4cf-4434-ad45-268cdd649a7f"
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(569, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDjmwTJrlHdo",
        "colab_type": "text"
      },
      "source": [
        "### Create First Hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5mftKAPZqdH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "04eba5e9-a80c-434a-8335-3c8fa4dd8d4c"
      },
      "source": [
        "classifier = Sequential()                                                        ## Inisialisasi ANN\n",
        "classifier.add(Dense(output_dim = 16, init = 'uniform', activation='relu'))     ## Hidden layers 1, dengan node inputnya (sebanyak jumlah kolom data)     \n",
        "classifier.add(Dropout(p=0.1))                                                  ## penggunaan DropOut layer untuk mencegah overfitting dengan nilai p=0.1"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXLwcb54dt4h",
        "colab_type": "text"
      },
      "source": [
        "Note:\n",
        "1. output_dim = jumlah node\n",
        "2. init = pemberian bobotnya\n",
        "3. activation = fungsi aktivasi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJ0pu-bDlMj4",
        "colab_type": "text"
      },
      "source": [
        "### Create Second Hidden Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH91TV75lQS4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "6aeedfcf-e865-4dc1-a2c3-065dd245cd03"
      },
      "source": [
        "classifier.add(Dense(output_dim = 16, init = 'uniform', activation='relu'))     ## Hidden layers 1, dengan node inputnya (sebanyak jumlah kolom data)     \n",
        "classifier.add(Dropout(p=0.1))                                                  ## penggunaan DropOut layer untuk mencegah overfitting dengan nilai p=0.1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.1)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p4aBj--rltxM",
        "colab_type": "text"
      },
      "source": [
        "### Create Output Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KzsWkn5lr4w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b03a36e8-487a-4b93-d40e-31b4c54cdfa6"
      },
      "source": [
        "classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))       ## fungsi aktivasi yg digunakan yaitu sigmoid (output = 0 atau 1)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A62t48GtmEqW",
        "colab_type": "text"
      },
      "source": [
        "## Training ANN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmhSDhkkl95n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Compile ANN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "## loss_function (binary), optimizer(adam for stochastic gradient descent)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3RisSZRmsqt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "952399a4-873f-4224-8049-83a3ec9628f6"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(398, 30)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DIhQkJjCnw_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "16586e7f-447c-4c34-f801-617a69f93cd9"
      },
      "source": [
        "y_train.value_counts()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    249\n",
              "1    149\n",
              "Name: label_diagnosis, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tl0mQi3VoNFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a4c73242-abbd-44e5-c928-2777cd89e4d4"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AwWXp0H0pSH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "9b891286-c7e1-490e-bdb5-6da74a2d8392"
      },
      "source": [
        "X_train"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.74998027, -1.09978744, -0.74158608, ..., -0.6235968 ,\n",
              "         0.07754241,  0.45062841],\n",
              "       [-1.02821446, -0.1392617 , -1.02980434, ..., -0.7612376 ,\n",
              "        -1.07145262, -0.29541379],\n",
              "       [-0.53852228, -0.29934933, -0.56857428, ..., -0.50470441,\n",
              "         0.34900827, -0.13371556],\n",
              "       ...,\n",
              "       [-1.3214733 , -0.20855336, -1.3143845 , ..., -0.98621857,\n",
              "        -0.69108476, -0.13148524],\n",
              "       [-1.24245479, -0.23244704, -1.27759928, ..., -1.7562754 ,\n",
              "        -1.55125275, -1.01078909],\n",
              "       [-0.74441558,  1.13188181, -0.72016173, ..., -0.28490593,\n",
              "        -1.2308599 ,  0.20083251]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRLOn3yP133Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "8c0b22a0-090a-423f-a390-fcb3bbbc7a1e"
      },
      "source": [
        "y_train.values"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
              "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1,\n",
              "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
              "       0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
              "       0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
              "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
              "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
              "       1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
              "       0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMj_HDea0tIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f993c69-583f-430d-f632-5bf24c410279"
      },
      "source": [
        "len(y_train)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lp6KV5FBmTib",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "87e60eae-f1cc-45db-92e9-d4beaa32788e"
      },
      "source": [
        "## Training ANN on the Training Set\n",
        "# note untuk labels(y_train) harus dalam bentuk numpy array\n",
        "classifier.fit(X_train, y_train.values, batch_size= 10, epochs=150)                    ## batch_size(jumlah sample untuk ANN melakukan training set), iterasi 150 kali"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "398/398 [==============================] - 0s 465us/step - loss: 0.6816 - accuracy: 0.6935\n",
            "Epoch 2/150\n",
            "398/398 [==============================] - 0s 119us/step - loss: 0.5534 - accuracy: 0.9095\n",
            "Epoch 3/150\n",
            "398/398 [==============================] - 0s 119us/step - loss: 0.3127 - accuracy: 0.9497\n",
            "Epoch 4/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.1760 - accuracy: 0.9573\n",
            "Epoch 5/150\n",
            "398/398 [==============================] - 0s 161us/step - loss: 0.1230 - accuracy: 0.9724\n",
            "Epoch 6/150\n",
            "398/398 [==============================] - 0s 153us/step - loss: 0.1059 - accuracy: 0.9724\n",
            "Epoch 7/150\n",
            "398/398 [==============================] - 0s 154us/step - loss: 0.1035 - accuracy: 0.9724\n",
            "Epoch 8/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0891 - accuracy: 0.9724\n",
            "Epoch 9/150\n",
            "398/398 [==============================] - 0s 152us/step - loss: 0.0886 - accuracy: 0.9799\n",
            "Epoch 10/150\n",
            "398/398 [==============================] - 0s 149us/step - loss: 0.0807 - accuracy: 0.9824\n",
            "Epoch 11/150\n",
            "398/398 [==============================] - 0s 151us/step - loss: 0.0752 - accuracy: 0.9849\n",
            "Epoch 12/150\n",
            "398/398 [==============================] - 0s 155us/step - loss: 0.0711 - accuracy: 0.9824\n",
            "Epoch 13/150\n",
            "398/398 [==============================] - 0s 148us/step - loss: 0.0741 - accuracy: 0.9849\n",
            "Epoch 14/150\n",
            "398/398 [==============================] - 0s 178us/step - loss: 0.0648 - accuracy: 0.9774\n",
            "Epoch 15/150\n",
            "398/398 [==============================] - 0s 159us/step - loss: 0.0662 - accuracy: 0.9824\n",
            "Epoch 16/150\n",
            "398/398 [==============================] - 0s 154us/step - loss: 0.0673 - accuracy: 0.9824\n",
            "Epoch 17/150\n",
            "398/398 [==============================] - 0s 158us/step - loss: 0.0561 - accuracy: 0.9849\n",
            "Epoch 18/150\n",
            "398/398 [==============================] - 0s 155us/step - loss: 0.0599 - accuracy: 0.9874\n",
            "Epoch 19/150\n",
            "398/398 [==============================] - 0s 162us/step - loss: 0.0669 - accuracy: 0.9874\n",
            "Epoch 20/150\n",
            "398/398 [==============================] - 0s 155us/step - loss: 0.0574 - accuracy: 0.9874\n",
            "Epoch 21/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0559 - accuracy: 0.9849\n",
            "Epoch 22/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0545 - accuracy: 0.9874\n",
            "Epoch 23/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0569 - accuracy: 0.9874\n",
            "Epoch 24/150\n",
            "398/398 [==============================] - 0s 137us/step - loss: 0.0482 - accuracy: 0.9874\n",
            "Epoch 25/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0485 - accuracy: 0.9874\n",
            "Epoch 26/150\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.0425 - accuracy: 0.9899\n",
            "Epoch 27/150\n",
            "398/398 [==============================] - 0s 127us/step - loss: 0.0469 - accuracy: 0.9874\n",
            "Epoch 28/150\n",
            "398/398 [==============================] - 0s 139us/step - loss: 0.0408 - accuracy: 0.9874\n",
            "Epoch 29/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0433 - accuracy: 0.9874\n",
            "Epoch 30/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0425 - accuracy: 0.9874\n",
            "Epoch 31/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0358 - accuracy: 0.9899\n",
            "Epoch 32/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0389 - accuracy: 0.9899\n",
            "Epoch 33/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0434 - accuracy: 0.9874\n",
            "Epoch 34/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0388 - accuracy: 0.9874\n",
            "Epoch 35/150\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.0322 - accuracy: 0.9899\n",
            "Epoch 36/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0339 - accuracy: 0.9899\n",
            "Epoch 37/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0354 - accuracy: 0.9899\n",
            "Epoch 38/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0357 - accuracy: 0.9849\n",
            "Epoch 39/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0316 - accuracy: 0.9874\n",
            "Epoch 40/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0298 - accuracy: 0.9899\n",
            "Epoch 41/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0336 - accuracy: 0.9899\n",
            "Epoch 42/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0299 - accuracy: 0.9874\n",
            "Epoch 43/150\n",
            "398/398 [==============================] - 0s 145us/step - loss: 0.0298 - accuracy: 0.9874\n",
            "Epoch 44/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0286 - accuracy: 0.9899\n",
            "Epoch 45/150\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.0255 - accuracy: 0.9899\n",
            "Epoch 46/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0315 - accuracy: 0.9874\n",
            "Epoch 47/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0282 - accuracy: 0.9874\n",
            "Epoch 48/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0269 - accuracy: 0.9899\n",
            "Epoch 49/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0235 - accuracy: 0.9899\n",
            "Epoch 50/150\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.0236 - accuracy: 0.9899\n",
            "Epoch 51/150\n",
            "398/398 [==============================] - 0s 135us/step - loss: 0.0229 - accuracy: 0.9925\n",
            "Epoch 52/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0223 - accuracy: 0.9925\n",
            "Epoch 53/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0247 - accuracy: 0.9899\n",
            "Epoch 54/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0231 - accuracy: 0.9925\n",
            "Epoch 55/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0216 - accuracy: 0.9899\n",
            "Epoch 56/150\n",
            "398/398 [==============================] - 0s 156us/step - loss: 0.0175 - accuracy: 0.9925\n",
            "Epoch 57/150\n",
            "398/398 [==============================] - 0s 160us/step - loss: 0.0226 - accuracy: 0.9925\n",
            "Epoch 58/150\n",
            "398/398 [==============================] - 0s 158us/step - loss: 0.0169 - accuracy: 0.9925\n",
            "Epoch 59/150\n",
            "398/398 [==============================] - 0s 148us/step - loss: 0.0186 - accuracy: 0.9925\n",
            "Epoch 60/150\n",
            "398/398 [==============================] - 0s 139us/step - loss: 0.0287 - accuracy: 0.9899\n",
            "Epoch 61/150\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.0177 - accuracy: 0.9925\n",
            "Epoch 62/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0155 - accuracy: 0.9925\n",
            "Epoch 63/150\n",
            "398/398 [==============================] - 0s 132us/step - loss: 0.0160 - accuracy: 0.9925\n",
            "Epoch 64/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0162 - accuracy: 0.9925\n",
            "Epoch 65/150\n",
            "398/398 [==============================] - 0s 169us/step - loss: 0.0187 - accuracy: 0.9899\n",
            "Epoch 66/150\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.0201 - accuracy: 0.9925\n",
            "Epoch 67/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0146 - accuracy: 0.9925\n",
            "Epoch 68/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0154 - accuracy: 0.9950\n",
            "Epoch 69/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0154 - accuracy: 0.9950\n",
            "Epoch 70/150\n",
            "398/398 [==============================] - 0s 149us/step - loss: 0.0158 - accuracy: 0.9950\n",
            "Epoch 71/150\n",
            "398/398 [==============================] - 0s 151us/step - loss: 0.0141 - accuracy: 0.9925\n",
            "Epoch 72/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0143 - accuracy: 0.9925\n",
            "Epoch 73/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0136 - accuracy: 0.9950\n",
            "Epoch 74/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0156 - accuracy: 0.9950\n",
            "Epoch 75/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0155 - accuracy: 0.9950\n",
            "Epoch 76/150\n",
            "398/398 [==============================] - 0s 157us/step - loss: 0.0174 - accuracy: 0.9950\n",
            "Epoch 77/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0197 - accuracy: 0.9950\n",
            "Epoch 78/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0165 - accuracy: 0.9925\n",
            "Epoch 79/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0142 - accuracy: 0.9925\n",
            "Epoch 80/150\n",
            "398/398 [==============================] - 0s 129us/step - loss: 0.0208 - accuracy: 0.9925\n",
            "Epoch 81/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0121 - accuracy: 0.9950\n",
            "Epoch 82/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0175 - accuracy: 0.9950\n",
            "Epoch 83/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0123 - accuracy: 0.9975\n",
            "Epoch 84/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0106 - accuracy: 0.9975\n",
            "Epoch 85/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0100 - accuracy: 0.9975\n",
            "Epoch 86/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0124 - accuracy: 0.9950\n",
            "Epoch 87/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0091 - accuracy: 0.9950\n",
            "Epoch 88/150\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.0143 - accuracy: 0.9975\n",
            "Epoch 89/150\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.0137 - accuracy: 0.9975\n",
            "Epoch 90/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0099 - accuracy: 0.9975\n",
            "Epoch 91/150\n",
            "398/398 [==============================] - 0s 121us/step - loss: 0.0100 - accuracy: 0.9975\n",
            "Epoch 92/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0091 - accuracy: 0.9975\n",
            "Epoch 93/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0082 - accuracy: 0.9975\n",
            "Epoch 94/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0101 - accuracy: 0.9975\n",
            "Epoch 95/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0077 - accuracy: 0.9975\n",
            "Epoch 96/150\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.0088 - accuracy: 0.9975\n",
            "Epoch 97/150\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.0143 - accuracy: 0.9950\n",
            "Epoch 98/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0111 - accuracy: 0.9950\n",
            "Epoch 99/150\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.0094 - accuracy: 0.9975\n",
            "Epoch 100/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0095 - accuracy: 0.9975\n",
            "Epoch 101/150\n",
            "398/398 [==============================] - 0s 146us/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 102/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0080 - accuracy: 0.9975\n",
            "Epoch 103/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0092 - accuracy: 0.9975\n",
            "Epoch 104/150\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.0084 - accuracy: 1.0000\n",
            "Epoch 105/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0072 - accuracy: 0.9975\n",
            "Epoch 106/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0076 - accuracy: 1.0000\n",
            "Epoch 107/150\n",
            "398/398 [==============================] - 0s 163us/step - loss: 0.0065 - accuracy: 0.9975\n",
            "Epoch 108/150\n",
            "398/398 [==============================] - 0s 184us/step - loss: 0.0059 - accuracy: 0.9975\n",
            "Epoch 109/150\n",
            "398/398 [==============================] - 0s 134us/step - loss: 0.0078 - accuracy: 1.0000\n",
            "Epoch 110/150\n",
            "398/398 [==============================] - 0s 163us/step - loss: 0.0097 - accuracy: 0.9975\n",
            "Epoch 111/150\n",
            "398/398 [==============================] - 0s 158us/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 112/150\n",
            "398/398 [==============================] - 0s 160us/step - loss: 0.0066 - accuracy: 1.0000\n",
            "Epoch 113/150\n",
            "398/398 [==============================] - 0s 156us/step - loss: 0.0074 - accuracy: 1.0000\n",
            "Epoch 114/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0058 - accuracy: 1.0000\n",
            "Epoch 115/150\n",
            "398/398 [==============================] - 0s 128us/step - loss: 0.0081 - accuracy: 0.9975\n",
            "Epoch 116/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0076 - accuracy: 0.9975\n",
            "Epoch 117/150\n",
            "398/398 [==============================] - 0s 130us/step - loss: 0.0056 - accuracy: 1.0000\n",
            "Epoch 118/150\n",
            "398/398 [==============================] - 0s 124us/step - loss: 0.0048 - accuracy: 1.0000\n",
            "Epoch 119/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 120/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 121/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0047 - accuracy: 1.0000\n",
            "Epoch 122/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 123/150\n",
            "398/398 [==============================] - 0s 131us/step - loss: 0.0037 - accuracy: 1.0000\n",
            "Epoch 124/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0049 - accuracy: 1.0000\n",
            "Epoch 125/150\n",
            "398/398 [==============================] - 0s 126us/step - loss: 0.0033 - accuracy: 1.0000\n",
            "Epoch 126/150\n",
            "398/398 [==============================] - 0s 133us/step - loss: 0.0050 - accuracy: 1.0000\n",
            "Epoch 127/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 128/150\n",
            "398/398 [==============================] - 0s 122us/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 129/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0060 - accuracy: 1.0000\n",
            "Epoch 130/150\n",
            "398/398 [==============================] - 0s 120us/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 131/150\n",
            "398/398 [==============================] - 0s 123us/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 132/150\n",
            "398/398 [==============================] - 0s 129us/step - loss: 0.0059 - accuracy: 1.0000\n",
            "Epoch 133/150\n",
            "398/398 [==============================] - 0s 137us/step - loss: 0.0035 - accuracy: 1.0000\n",
            "Epoch 134/150\n",
            "398/398 [==============================] - 0s 164us/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 135/150\n",
            "398/398 [==============================] - 0s 172us/step - loss: 0.0034 - accuracy: 1.0000\n",
            "Epoch 136/150\n",
            "398/398 [==============================] - 0s 154us/step - loss: 0.0051 - accuracy: 1.0000\n",
            "Epoch 137/150\n",
            "398/398 [==============================] - 0s 167us/step - loss: 0.0063 - accuracy: 0.9975\n",
            "Epoch 138/150\n",
            "398/398 [==============================] - 0s 161us/step - loss: 0.0044 - accuracy: 1.0000\n",
            "Epoch 139/150\n",
            "398/398 [==============================] - 0s 162us/step - loss: 0.0032 - accuracy: 1.0000\n",
            "Epoch 140/150\n",
            "398/398 [==============================] - 0s 157us/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 141/150\n",
            "398/398 [==============================] - 0s 158us/step - loss: 0.0095 - accuracy: 0.9975\n",
            "Epoch 142/150\n",
            "398/398 [==============================] - 0s 171us/step - loss: 0.0070 - accuracy: 0.9975\n",
            "Epoch 143/150\n",
            "398/398 [==============================] - 0s 178us/step - loss: 0.0038 - accuracy: 1.0000\n",
            "Epoch 144/150\n",
            "398/398 [==============================] - 0s 156us/step - loss: 0.0030 - accuracy: 1.0000\n",
            "Epoch 145/150\n",
            "398/398 [==============================] - 0s 158us/step - loss: 0.0068 - accuracy: 0.9975\n",
            "Epoch 146/150\n",
            "398/398 [==============================] - 0s 152us/step - loss: 0.0356 - accuracy: 0.9950\n",
            "Epoch 147/150\n",
            "398/398 [==============================] - 0s 166us/step - loss: 0.0040 - accuracy: 1.0000\n",
            "Epoch 148/150\n",
            "398/398 [==============================] - 0s 150us/step - loss: 0.0028 - accuracy: 1.0000\n",
            "Epoch 149/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0072 - accuracy: 0.9975\n",
            "Epoch 150/150\n",
            "398/398 [==============================] - 0s 125us/step - loss: 0.0034 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f1c30e08908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAiizym63vw3",
        "colab_type": "text"
      },
      "source": [
        "## Prediksi"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsujU95nnMKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bd94c591-d25d-42c0-fca9-e5039c66546b"
      },
      "source": [
        "y_pred = classifier.predict(X_test)\n",
        "y_pred"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00],\n",
              "       [1.9564927e-03],\n",
              "       [1.3301248e-11],\n",
              "       [6.2429785e-07],\n",
              "       [8.0383884e-15],\n",
              "       [3.7025761e-11],\n",
              "       [3.2707741e-18],\n",
              "       [3.1478349e-12],\n",
              "       [1.1666756e-10],\n",
              "       [5.0826524e-27],\n",
              "       [8.8353330e-01],\n",
              "       [1.1071861e-03],\n",
              "       [1.3322333e-17],\n",
              "       [9.9755347e-01],\n",
              "       [9.9992388e-01],\n",
              "       [1.0000000e+00],\n",
              "       [1.9516096e-17],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.9393193e-10],\n",
              "       [8.2716591e-11],\n",
              "       [1.0000000e+00],\n",
              "       [1.7741814e-12],\n",
              "       [5.5589271e-14],\n",
              "       [1.0000000e+00],\n",
              "       [8.3145053e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.1130096e-14],\n",
              "       [1.0000000e+00],\n",
              "       [7.2237926e-05],\n",
              "       [1.0000000e+00],\n",
              "       [1.1676442e-21],\n",
              "       [1.0000000e+00],\n",
              "       [9.8087658e-06],\n",
              "       [1.0000000e+00],\n",
              "       [1.0183464e-09],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999666e-01],\n",
              "       [8.2205420e-15],\n",
              "       [9.9999839e-01],\n",
              "       [2.1825187e-15],\n",
              "       [8.0358982e-09],\n",
              "       [1.0000000e+00],\n",
              "       [9.2712045e-23],\n",
              "       [1.6112774e-05],\n",
              "       [3.0867100e-15],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.1224884e-12],\n",
              "       [3.6013483e-13],\n",
              "       [2.1140700e-12],\n",
              "       [8.3692268e-11],\n",
              "       [4.8729174e-07],\n",
              "       [3.0477149e-06],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [2.7546133e-19],\n",
              "       [7.1276684e-14],\n",
              "       [1.0000000e+00],\n",
              "       [2.6534408e-02],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.8085997e-10],\n",
              "       [9.5292771e-01],\n",
              "       [1.0000000e+00],\n",
              "       [6.1321150e-11],\n",
              "       [9.9958014e-01],\n",
              "       [1.0000000e+00],\n",
              "       [4.4739246e-04],\n",
              "       [2.6369708e-16],\n",
              "       [1.8568595e-12],\n",
              "       [4.4390255e-11],\n",
              "       [1.5149385e-15],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [3.6182526e-16],\n",
              "       [1.0000000e+00],\n",
              "       [3.1245863e-14],\n",
              "       [8.5603087e-16],\n",
              "       [8.7344537e-21],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [2.7737331e-17],\n",
              "       [9.9864316e-01],\n",
              "       [9.6150064e-01],\n",
              "       [1.0000000e+00],\n",
              "       [3.4811056e-09],\n",
              "       [8.0925813e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.6757530e-14],\n",
              "       [7.0035564e-09],\n",
              "       [1.1755428e-11],\n",
              "       [0.0000000e+00],\n",
              "       [6.1963595e-10],\n",
              "       [6.2170769e-10],\n",
              "       [4.8874106e-05],\n",
              "       [1.0000000e+00],\n",
              "       [1.2705078e-18],\n",
              "       [1.0000000e+00],\n",
              "       [9.9863863e-01],\n",
              "       [5.6475967e-02],\n",
              "       [1.1423856e-02],\n",
              "       [6.2527386e-07],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.2288530e-01],\n",
              "       [4.5906200e-12],\n",
              "       [2.3359966e-05],\n",
              "       [3.6503673e-07],\n",
              "       [9.5679527e-11],\n",
              "       [4.4560432e-04],\n",
              "       [4.2142227e-15],\n",
              "       [3.9748634e-06],\n",
              "       [1.7641425e-12],\n",
              "       [4.6463743e-11],\n",
              "       [7.6023426e-10],\n",
              "       [1.0000000e+00],\n",
              "       [3.3493405e-05],\n",
              "       [6.8420506e-01],\n",
              "       [1.3408510e-15],\n",
              "       [9.6093281e-21],\n",
              "       [1.2799469e-15],\n",
              "       [1.0000000e+00],\n",
              "       [2.6992408e-13],\n",
              "       [1.5386032e-13],\n",
              "       [1.9057350e-06],\n",
              "       [1.4909646e-12],\n",
              "       [1.3708547e-21],\n",
              "       [8.6808628e-01],\n",
              "       [9.9978775e-01],\n",
              "       [1.0000000e+00],\n",
              "       [2.4623351e-18],\n",
              "       [7.8951678e-13],\n",
              "       [7.5252950e-20],\n",
              "       [1.0000000e+00],\n",
              "       [7.4196045e-11],\n",
              "       [3.6262809e-16],\n",
              "       [1.0000000e+00],\n",
              "       [4.4229387e-07],\n",
              "       [9.9653721e-01],\n",
              "       [1.3309560e-09],\n",
              "       [3.8155612e-09],\n",
              "       [8.9858120e-14],\n",
              "       [6.6999922e-17],\n",
              "       [1.0735161e-09],\n",
              "       [1.4987621e-01],\n",
              "       [1.2071279e-15],\n",
              "       [1.0000000e+00],\n",
              "       [6.2967035e-07],\n",
              "       [9.9999142e-01],\n",
              "       [1.8766273e-12],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [9.6282322e-12],\n",
              "       [1.9207815e-09],\n",
              "       [1.0000000e+00],\n",
              "       [2.1354534e-14],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [1.0000000e+00],\n",
              "       [3.5111478e-04],\n",
              "       [4.3424317e-09],\n",
              "       [1.0778921e-17]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0cTjl0u5mBL",
        "colab_type": "text"
      },
      "source": [
        "### create threshold to define labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckP2rMaY7i2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee8ec91c-bace-483c-a047-9ebd8cd2ad09"
      },
      "source": [
        "thld = (y_pred>0.5).astype(int)                     ## untuk nilai probabilitas >0.5 akan masuk kedalam kelas 1\n",
        "thld"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [1],\n",
              "       [0],\n",
              "       [1],\n",
              "       [1],\n",
              "       [1],\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNulFtEH8fS4",
        "colab_type": "text"
      },
      "source": [
        "### Actual vs Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzsx5hbQ4TIA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cb6f681e-cfc2-4a66-db83-3c5996fc6c30"
      },
      "source": [
        "print(np.concatenate((thld.reshape(len(thld), 1), y_test.values.reshape(len(y_test), 1)),1))\n",
        "\n",
        "## note untuk yang index ke 0 merupakan prediksi, dan index ke 1 merupakan actual resultnya (labels)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [1 1]\n",
            " [0 0]\n",
            " [0 0]\n",
            " [0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRqprc_G89Vk",
        "colab_type": "text"
      },
      "source": [
        "## Counfusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4f_Q29z5421",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "2fdf260f-a041-460f-c623-d82222136072"
      },
      "source": [
        "\n",
        "cm = confusion_matrix(y_test, thld)\n",
        "sns.heatmap(cm, annot=True)\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1c30d3ada0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkpg8J4P9i0E",
        "colab_type": "text"
      },
      "source": [
        "### Scoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkyUrxWv9KEh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "740c01d0-2d72-4927-ee0d-65d41446e4d9"
      },
      "source": [
        "## Akurasi\n",
        "accuracy_score(y_test, thld)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9298245614035088"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccYZN1CASNcm",
        "colab_type": "text"
      },
      "source": [
        "## Save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhkWnJ1v9pBb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickling_on = open(\"Breast_Cancer.pkl\",\"wb\")\n",
        "pickle.dump(classifier, pickling_on)\n",
        "pickling_on.close()\n",
        "\n",
        "NN_model = pickle.load(open(r\"Breast_Cancer.pkl\", 'rb'))"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}